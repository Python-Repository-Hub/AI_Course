{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Access pixel values and modify >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_img = cv2.imread(data_path + 'blox.jpg', 1)\n",
    "block_img = cv2.cvtColor(block_img, cv2.COLOR_BGR2RGB)\n",
    "print(block_img.shape)\n",
    "plt.imshow(block_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(block_img[79:132, 170:206,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_img[79:132, 170:206,:] = block_img[79,170,:]\n",
    "plt.imshow(block_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball_img = cv2.imread(data_path+'baseball_player.jpg')\n",
    "baseball_img = cv2.cvtColor(baseball_img, cv2.COLOR_BGR2RGB)\n",
    "print(baseball_img.shape)\n",
    "plt.imshow(baseball_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to do : Make it look like two balls\n",
    "# ball [305:332, 614:641]\n",
    "baseball_img = cv2.imread(data_path+'baseball_player.jpg')\n",
    "baseball_img = cv2.cvtColor(baseball_img, cv2.COLOR_BGR2RGB)\n",
    "baseball_img[345:372, 614:641, :]= baseball_img[305:332, 614:641, :]\n",
    "plt.imshow(baseball_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Image Histogram >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_img = cv2.imread(data_path+\"building.jpg\", 0)\n",
    "#building_img = cv2.cvtColor(building_img, cv2.COLOR_BGR2RGB)\n",
    "print(building_img.shape)\n",
    "height = building_img.shape[0]\n",
    "width = building_img.shape[1]\n",
    "plt.imshow(building_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n",
    " \n",
    "images : Source image\n",
    "\n",
    "channels : If input is grayscale image, its value is [0]. For color image, you can pass [0],[1] or [2] to calculate histogram of blue,green or red channel respectively.\n",
    "\n",
    "mask : If you want to find histogram of particular region of image, you have to create a mask image for that and give it as mask.\n",
    "\n",
    "histSize : This represents our BIN count.\n",
    "\n",
    "ranges : This is our RANGE. Normally, it is [0,256]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calchist1 = cv2.calcHist([building_img], [0], None, [256], [0,256])\n",
    "plt.plot(calchist1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogram Equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.equalizeHist(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_img = cv2.imread(data_path+\"building.jpg\", 0)\n",
    "eq_img1 = cv2.equalizeHist(building_img)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2, figsize=(20,8))\n",
    "building_img = cv2.cvtColor(building_img, cv2.COLOR_BGR2RGB)\n",
    "eq_img1 = cv2.cvtColor(eq_img1, cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(building_img)\n",
    "ax2.imshow(eq_img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.createCLAHE(clipLimit, tileGridSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "building_img = cv2.imread(data_path+\"building.jpg\", 0)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "eq_img2 = clahe.apply(building_img)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2, figsize=(20,8))\n",
    "building_img = cv2.cvtColor(building_img, cv2.COLOR_BGR2RGB)\n",
    "eq_img2 = cv2.cvtColor(eq_img2, cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(building_img)\n",
    "ax2.imshow(eq_img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## < Image Thresholding >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.threshold(src, thresh, maxval, type) â†’ retval, dst \n",
    "If pixel value is greater than a threshold value, it is assigned one value (may be white), else it is assigned another value (may be black).\n",
    " \n",
    "- thresholding type\n",
    "\n",
    "cv2.THRESH_BINARY\n",
    "\n",
    "cv2.THRESH_BINARY_INV\n",
    "\n",
    "cv2.THRESH_TRUNC\n",
    "\n",
    "cv2.THRESH_TOZERO\n",
    "\n",
    "cv2.THRESH_TOZERO_INV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_img = cv2.imread(data_path + \"gradient.png\", 1)\n",
    "plt.imshow(gradient_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh1 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_TRUNC)\n",
    "ret, thresh4 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh5 = cv2.threshold(gradient_img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = [\"Original\", \"Binary\", \"Binary_inv\", \"Trunc\", \"ToZero\", \"ToZero_inv\"]\n",
    "imgs = [gradient_img, thresh1, thresh2, thresh3 ,thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3, i+1)\n",
    "    plt.imshow(imgs[i])\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C)\n",
    "\n",
    "- Adaptive Method\n",
    "\n",
    "cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "\n",
    "cv2.ADAPTIVE_THRESH_GAUSSIAN_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sudoku_img = cv2.imread(data_path + 'sudoku.png',0)\n",
    "\n",
    "ret, th1 = cv2.threshold(sudoku_img,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "th2 = cv2.adaptiveThreshold(sudoku_img,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,15,2)\n",
    "\n",
    "th3 = cv2.adaptiveThreshold(sudoku_img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,15,2)\n",
    "\n",
    "titles = ['Original','Global','Mean','Gaussian']\n",
    "images = [sudoku_img,th1,th2,th3]\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,10))\n",
    "sudoku_img = cv2.cvtColor(sudoku_img, cv2.COLOR_BGR2RGB)\n",
    "th1 = cv2.cvtColor(th1, cv2.COLOR_BGR2RGB)\n",
    "th2 = cv2.cvtColor(th2, cv2.COLOR_BGR2RGB)\n",
    "th3 = cv2.cvtColor(th3, cv2.COLOR_BGR2RGB)\n",
    "ax1.imshow(sudoku_img)\n",
    "ax2.imshow(th1)\n",
    "ax3.imshow(th2)\n",
    "ax4.imshow(th3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### otsu binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lena_img_c = cv2.imread(data_path+\"lena_noisy.jpg\", 1)\n",
    "\n",
    "lena_img = cv2.imread(data_path+\"lena_noisy.jpg\", 0)\n",
    "\n",
    "ret1, th = cv2.threshold(lena_img, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "ret2, otsu1 = cv2.threshold(lena_img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "blur = cv2.GaussianBlur(lena_img,(5,5),0)\n",
    "ret, otsu2 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "print(ret1, ret2)\n",
    "\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,10))\n",
    "\n",
    "lena_img_c = cv2.cvtColor(lena_img_c, cv2.COLOR_BGR2RGB) \n",
    "th = cv2.cvtColor(th, cv2.COLOR_BGR2RGB)\n",
    "otsu1 = cv2.cvtColor(otsu1, cv2.COLOR_BGR2RGB)\n",
    "otsu2 = cv2.cvtColor(otsu2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "ax1.imshow(lena_img_c)\n",
    "ax2.imshow(th)\n",
    "ax3.imshow(otsu1)\n",
    "ax4.imshow(otsu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
